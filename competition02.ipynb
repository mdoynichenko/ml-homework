{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d7c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf997b",
   "metadata": {},
   "source": [
    "Модель: усредненное значение пяти ансамблей.\n",
    "\n",
    "Набор данных разбит на 5 частей, каждый ансамбль обучается на своих четырех частях.\n",
    "\n",
    "Метаалгоритм -- линейная регрессия.\n",
    "\n",
    "Алгоритмы первого уровня:\n",
    "\n",
    "1. kNN\n",
    "2. Случайный лес\n",
    "3. Градиентный бустинг\n",
    "4. Градиентный бустинг с гистограммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0074292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "X_pd = train.copy()\n",
    "\n",
    "marks_dict = {\n",
    "    'no data':0,\n",
    "    'poor':1,\n",
    "    'satisfactory':2,\n",
    "    'good':3,\n",
    "    'excellent':4 \n",
    "}\n",
    "marks_text = X_pd['f152'].unique()\n",
    "\n",
    "X_pd['f1_time'] = X_pd['f1'].apply(lambda x: int(dt.datetime.strptime(x, \"%Y-%m-%d\").timestamp()))\n",
    "for text in X_pd['f152'].unique():\n",
    "    X_pd['f152'].replace(text, marks_dict[text], inplace=True)\n",
    "    \n",
    "X_pd['f11'].replace('OwnerOccupier', 65, inplace=True)\n",
    "X_pd['f11'].replace('Investment', 75, inplace = True)\n",
    "\n",
    "for col in ['f29', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f106', 'f114', 'f118']:\n",
    "    X_pd[col].replace('no', 0, inplace=True)\n",
    "    X_pd[col].replace('yes', 1, inplace = True)\n",
    "X_pd.drop(columns=['f291', 'id', 'f1'], inplace = True)\n",
    "y_pd = train['f291']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e49f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = pd.read_csv('test.csv')\n",
    "testX_pr = testX.copy()\n",
    "\n",
    "testX['f1_time'] = testX['f1'].apply(lambda x: int(dt.datetime.strptime(x, \"%Y-%m-%d\").timestamp()))\n",
    "for text in ['no data', 'poor', 'satisfactory', 'good', 'excellent']:\n",
    "    testX['f152'].replace(text, marks_dict[text], inplace=True)\n",
    "testX['f11'].replace('OwnerOccupier', 65, inplace=True)\n",
    "testX['f11'].replace('Investment', 75, inplace = True)\n",
    "for col in ['f29', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f106', 'f114', 'f118']:\n",
    "    testX[col].replace('no', 0, inplace=True)\n",
    "    testX[col].replace('yes', 1, inplace = True)\n",
    "testX.drop(columns=['id', 'f1'], inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93579218",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = []\n",
    "for i in range(len(X_pd['f12'].unique())):\n",
    "    col_names.append('Is '+str(i))\n",
    "\n",
    "    \n",
    "testX.index = list(range(24736, 24736+6095))    \n",
    "big = pd.concat([testX, X_pd])\n",
    "big = big.sort_index()\n",
    "    \n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(big[['f12']]).toarray(), columns = col_names)\n",
    "big = big.join(enc_df)\n",
    "big.drop(columns=['f12'], inplace=True)\n",
    "X_pd = big.loc[:24376, :]\n",
    "testX = big.loc[24376:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d2da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24376, 435)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_imp = KNNImputer(n_neighbors=10, weights='distance')\n",
    "X_pd = my_imp.fit_transform(X_pd)\n",
    "np.save('X_pd_kNN_diff10', X_pd)\n",
    "\n",
    "X_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31507473",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = my_imp.transform(testX)\n",
    "np.save('testX_pd_kNN10', testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411557f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24376, 435), (24376,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_pd\n",
    "y = np.array(y_pd)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdbef1",
   "metadata": {},
   "source": [
    "Здесь пытаемся обучить kNN с весами distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b718c941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++\n",
      "0.5703885253991824 [k=1, neigh=20]\n",
      "0.5754986517001063 [k=1, neigh=20]\n",
      "0.5911248140818299 [k=1, neigh=20]\n",
      "+++++++++++\n",
      "0.5695006613551054 [k=1, neigh=22]\n",
      "0.5749971094361351 [k=1, neigh=22]\n",
      "0.5904592658456379 [k=1, neigh=22]\n",
      "+++++++++++\n",
      "0.5691952677065695 [k=1, neigh=24]\n",
      "0.5744094190757559 [k=1, neigh=24]\n",
      "0.5903805923886927 [k=1, neigh=24]\n",
      "+++++++++++\n",
      "0.5684914316868126 [k=1, neigh=26]\n",
      "0.5738176046285969 [k=1, neigh=26]\n",
      "0.5899453535736776 [k=1, neigh=26]\n",
      "+++++++++++\n",
      "0.5683971921042209 [k=1, neigh=28]\n",
      "0.5734085854342993 [k=1, neigh=28]\n",
      "0.5900173597399162 [k=1, neigh=28]\n",
      "+++++++++++\n",
      "0.5682121452316189 [k=1, neigh=30]\n",
      "0.5730566672603853 [k=1, neigh=30]\n",
      "0.5901685579134256 [k=1, neigh=30]\n",
      "+++++++++++\n",
      "0.5681145780298438 [k=1, neigh=32]\n",
      "0.5731662361071416 [k=1, neigh=32]\n",
      "0.5896797567045062 [k=1, neigh=32]\n",
      "+++++++++++\n",
      "0.5679476499701146 [k=1, neigh=34]\n",
      "0.5726547745636241 [k=1, neigh=34]\n",
      "0.589486679458409 [k=1, neigh=34]\n",
      "+++++++++++\n",
      "0.5676230181617676 [k=1, neigh=36]\n",
      "0.5725828396665364 [k=1, neigh=36]\n",
      "0.5894071221174195 [k=1, neigh=36]\n",
      "+++++++++++\n",
      "0.5676326647021781 [k=1, neigh=38]\n",
      "0.5725033013050028 [k=1, neigh=38]\n",
      "0.5894734682311863 [k=1, neigh=38]\n"
     ]
    }
   ],
   "source": [
    "X_fixed = X_pd\n",
    "y_fixed = y_pd\n",
    "\n",
    "\n",
    "for neigh in range(20,40,2):\n",
    "    for k in [1]:\n",
    "        print('+++++++++++')\n",
    "        my_kf = KFold(n_splits = 3)\n",
    "        for train_index, test_index in my_kf.split(X_fixed):\n",
    "            X_train, X_test = X_fixed[train_index], X_fixed[test_index]\n",
    "            y_train, y_test = y_fixed[train_index], y_fixed[test_index]\n",
    "            knnClassifier = KNeighborsRegressor(n_neighbors=neigh, p = k, weights='distance', n_jobs=-1)\n",
    "            knnClassifier.fit(X_train, y_train)\n",
    "            tmp_res = knnClassifier.predict(X_test)\n",
    "            accur = mean_squared_log_error(y_test, tmp_res.round(), squared=False)\n",
    "            print('{0} [k={1}, neigh={2}]'.format(accur, k, neigh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e017928",
   "metadata": {},
   "source": [
    "Самый оптимальный вариант в итоге был с 36 соседями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030dbbd",
   "metadata": {},
   "source": [
    "Тут обучаем линейную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d8d8742",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.7964752699470137\n",
      "LR: 0.5271143976059428\n",
      "LR: 0.5328429521998025\n",
      "LR: 0.5419605197610966\n",
      "LR: 0.5341319043537456\n",
      "LR: 0.5375031145407737\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_fixed[train_index], y_fixed[test_index]\n\u001b[0;32m     10\u001b[0m my_lr \u001b[38;5;241m=\u001b[39m LinearRegression(positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmy_lr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m tmp_res \u001b[38;5;241m=\u001b[39m my_lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     13\u001b[0m accur \u001b[38;5;241m=\u001b[39m mean_squared_log_error(y_test, \u001b[38;5;28mabs\u001b[39m(tmp_res), squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:685\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive:\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_residues \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnnls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m         \u001b[38;5;66;03m# scipy.optimize.nnls cannot handle y with shape (M, K)\u001b[39;00m\n\u001b[0;32m    688\u001b[0m         outs \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs_)(\n\u001b[0;32m    689\u001b[0m             delayed(optimize\u001b[38;5;241m.\u001b[39mnnls)(X, y[:, j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    690\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_nnls.py:80\u001b[0m, in \u001b[0;36mnnls\u001b[1;34m(A, b, maxiter)\u001b[0m\n\u001b[0;32m     77\u001b[0m zz \u001b[38;5;241m=\u001b[39m zeros((m,), dtype\u001b[38;5;241m=\u001b[39mdouble)\n\u001b[0;32m     78\u001b[0m index \u001b[38;5;241m=\u001b[39m zeros((n,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m x, rnorm, mode \u001b[38;5;241m=\u001b[39m __nnls\u001b[38;5;241m.\u001b[39mnnls(A, m, n, b, w, zz, index, maxiter)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo many iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_fixed = X_pd\n",
    "y_fixed = y_pd\n",
    "n_spl = 10\n",
    "\n",
    "my_kf = KFold(n_splits = n_spl)\n",
    "tot_accur = 0\n",
    "for train_index, test_index in my_kf.split(X_fixed):\n",
    "    X_train, X_test = X_fixed[train_index], X_fixed[test_index]\n",
    "    y_train, y_test = y_fixed[train_index], y_fixed[test_index]\n",
    "    my_lr = LinearRegression(positive=True)\n",
    "    my_lr.fit(X_train, y_train)\n",
    "    tmp_res = my_lr.predict(X_test)\n",
    "    accur = mean_squared_log_error(y_test, abs(tmp_res), squared=False)\n",
    "    tot_accur += accur\n",
    "    print('LR: {0}'.format(accur))\n",
    "    \n",
    "print(tot_accur/n_spl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a18d1",
   "metadata": {},
   "source": [
    "Обучим случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ca8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: 0.47287702708992635\n",
      "Random forest: 0.47435584442871565\n",
      "Random forest: 0.4920860279519843\n"
     ]
    }
   ],
   "source": [
    "X_fixed = X_pd\n",
    "y_fixed = y_pd\n",
    "\n",
    "my_kf = KFold(n_splits = 3)\n",
    "for train_index, test_index in my_kf.split(X_fixed):\n",
    "    X_train, X_test = X_fixed[train_index], X_fixed[test_index]\n",
    "    y_train, y_test = y_fixed[train_index], y_fixed[test_index]\n",
    "    my_clf = RandomForestRegressor(n_estimators=150, n_jobs = -1)\n",
    "    my_clf.fit(X_train, y_train)\n",
    "\n",
    "    tmp_res = my_clf.predict(X_test)\n",
    "\n",
    "    accur = mean_squared_log_error(y_test, abs(tmp_res), squared=False)\n",
    "    print('Random forest: {0}'.format(accur))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adeb2ec",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9c691a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++\n",
      "estim = 100, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.4734022610145012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_fixed[train_index], y_fixed[test_index]\n\u001b[0;32m     15\u001b[0m my_clf \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39mestim, max_depth\u001b[38;5;241m=\u001b[39mm_depth, loss\u001b[38;5;241m=\u001b[39mloss)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmy_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m tmp_res \u001b[38;5;241m=\u001b[39m my_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     20\u001b[0m accur \u001b[38;5;241m=\u001b[39m mean_squared_log_error(y_test, \u001b[38;5;28mabs\u001b[39m(tmp_res), squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    656\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    657\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    658\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    659\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:246\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    243\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    245\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 246\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    249\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    250\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    251\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_fixed = X_pd\n",
    "y_fixed = y_pd\n",
    "\n",
    "\n",
    "for estim in range(36,38,10):\n",
    "    for m_depth in range(5,13,2):\n",
    "        for loss in ['squared_error']:\n",
    "            print('++++++++')\n",
    "            print('estim = {0}, max_depth= {1}, loss = {2}'.format(estim, m_depth, loss))\n",
    "            my_kf = KFold(n_splits = 3)\n",
    "            for train_index, test_index in my_kf.split(X_fixed):\n",
    "                X_train, X_test = X_fixed[train_index], X_fixed[test_index]\n",
    "                y_train, y_test = y_fixed[train_index], y_fixed[test_index]\n",
    "\n",
    "                my_clf = GradientBoostingRegressor(n_estimators=estim, max_depth=m_depth, loss=loss)\n",
    "                my_clf.fit(X_train, y_train)\n",
    "\n",
    "                tmp_res = my_clf.predict(X_test)\n",
    "\n",
    "                accur = mean_squared_log_error(y_test, abs(tmp_res), squared=False)\n",
    "                print('Gradient boosting: {0}'.format(accur))\n",
    "                \n",
    "my_clf.feature_importance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e3777",
   "metadata": {},
   "source": [
    "Градиентный бустинг с гистограммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89198ed3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++\n",
      "max_leaf_nodes = 20, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.4605381986312555\n",
      "Gradient boosting: 0.4668740461065695\n",
      "Gradient boosting: 0.4855899358896991\n",
      "++++++++\n",
      "max_leaf_nodes = 20, max_depth= 7, loss = squared_error\n",
      "Gradient boosting: 0.4636511319083091\n",
      "Gradient boosting: 0.4675882445475966\n",
      "Gradient boosting: 0.4848098352887786\n",
      "++++++++\n",
      "max_leaf_nodes = 20, max_depth= 9, loss = squared_error\n",
      "Gradient boosting: 0.45946850171705705\n",
      "Gradient boosting: 0.47054462157761284\n",
      "Gradient boosting: 0.48278661262958394\n",
      "++++++++\n",
      "max_leaf_nodes = 25, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.4621921248352332\n",
      "Gradient boosting: 0.4688988432480071\n",
      "Gradient boosting: 0.48495162170423595\n",
      "++++++++\n",
      "max_leaf_nodes = 25, max_depth= 7, loss = squared_error\n",
      "Gradient boosting: 0.45843964135140275\n",
      "Gradient boosting: 0.46666868748165014\n",
      "Gradient boosting: 0.4840735101687848\n",
      "++++++++\n",
      "max_leaf_nodes = 25, max_depth= 9, loss = squared_error\n",
      "Gradient boosting: 0.4577757126894467\n",
      "Gradient boosting: 0.4668783151626167\n",
      "Gradient boosting: 0.4856155182585449\n",
      "++++++++\n",
      "max_leaf_nodes = 30, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.46322959483828224\n",
      "Gradient boosting: 0.4697945432994804\n",
      "Gradient boosting: 0.4851543693054031\n",
      "++++++++\n",
      "max_leaf_nodes = 30, max_depth= 7, loss = squared_error\n",
      "Gradient boosting: 0.46211186287760925\n",
      "Gradient boosting: 0.46717335139616645\n",
      "Gradient boosting: 0.4857883727853561\n",
      "++++++++\n",
      "max_leaf_nodes = 30, max_depth= 9, loss = squared_error\n",
      "Gradient boosting: 0.45777304210437636\n",
      "Gradient boosting: 0.4644415344622712\n",
      "Gradient boosting: 0.48449608786676146\n",
      "++++++++\n",
      "max_leaf_nodes = 35, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.4597025631981217\n",
      "Gradient boosting: 0.46673694359429496\n",
      "Gradient boosting: 0.48428590710977204\n",
      "++++++++\n",
      "max_leaf_nodes = 35, max_depth= 7, loss = squared_error\n",
      "Gradient boosting: 0.4608951816702875\n",
      "Gradient boosting: 0.4656760098383732\n",
      "Gradient boosting: 0.4841347999229483\n",
      "++++++++\n",
      "max_leaf_nodes = 35, max_depth= 9, loss = squared_error\n",
      "Gradient boosting: 0.4570970399516528\n",
      "Gradient boosting: 0.46950466728335\n",
      "Gradient boosting: 0.48561604137238135\n",
      "++++++++\n",
      "max_leaf_nodes = 40, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.46285445377307727\n",
      "Gradient boosting: 0.46853380486384694\n",
      "Gradient boosting: 0.4844772019192469\n",
      "++++++++\n",
      "max_leaf_nodes = 40, max_depth= 7, loss = squared_error\n",
      "Gradient boosting: 0.46743191054571576\n",
      "Gradient boosting: 0.46776958737358953\n",
      "Gradient boosting: 0.4834326620916963\n",
      "++++++++\n",
      "max_leaf_nodes = 40, max_depth= 9, loss = squared_error\n",
      "Gradient boosting: 0.4590438831387571\n",
      "Gradient boosting: 0.46492601990708204\n",
      "Gradient boosting: 0.48445462373103443\n",
      "++++++++\n",
      "max_leaf_nodes = 45, max_depth= 5, loss = squared_error\n",
      "Gradient boosting: 0.46450102615460565\n",
      "Gradient boosting: 0.4687066989798168\n",
      "Gradient boosting: 0.4841007725961448\n",
      "++++++++\n",
      "max_leaf_nodes = 45, max_depth= 7, loss = squared_error\n",
      "Gradient boosting: 0.45979241643768587\n",
      "Gradient boosting: 0.466920992842693\n",
      "Gradient boosting: 0.48341554025998795\n",
      "++++++++\n",
      "max_leaf_nodes = 45, max_depth= 9, loss = squared_error\n",
      "Gradient boosting: 0.4575647495186735\n",
      "Gradient boosting: 0.4659100587803772\n",
      "Gradient boosting: 0.48543640500602425\n"
     ]
    }
   ],
   "source": [
    "X_fixed = X_pd\n",
    "y_fixed = y_pd\n",
    "\n",
    "\n",
    "for max_leaf_nodes in range(20,50,5):\n",
    "    for m_depth in range(5,10,2):\n",
    "        for loss in ['squared_error']:\n",
    "            print('++++++++')\n",
    "            print('max_leaf_nodes = {0}, max_depth= {1}, loss = {2}'.format(max_leaf_nodes, m_depth, loss))\n",
    "            my_kf = KFold(n_splits = 3)\n",
    "            for train_index, test_index in my_kf.split(X_fixed):\n",
    "                X_train, X_test = X_fixed[train_index], X_fixed[test_index]\n",
    "                y_train, y_test = y_fixed[train_index], y_fixed[test_index]\n",
    "\n",
    "                my_clf = HistGradientBoostingRegressor(max_iter=160, max_depth=m_depth, loss=loss, max_leaf_nodes=max_leaf_nodes)\n",
    "                my_clf.fit(X_train, y_train)\n",
    "\n",
    "                tmp_res = my_clf.predict(X_test)\n",
    "\n",
    "                accur = mean_squared_log_error(y_test, abs(tmp_res), squared=False)\n",
    "                print('Gradient boosting: {0}'.format(accur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f522b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_pd, y_pd, train_size=0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b09e065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24376, 435), (6095, 435))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pd.shape, testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027aeaf",
   "metadata": {},
   "source": [
    "Усредняем несколько ансамблей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46093b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models\n",
      "Meta LR\n",
      "Base Models\n",
      "Meta LR\n",
      "Base Models\n",
      "Meta LR\n",
      "Base Models\n",
      "Meta LR\n",
      "Base Models\n",
      "Meta LR\n",
      "Model is done\n"
     ]
    }
   ],
   "source": [
    "my_kf = KFold(n_splits = 5)\n",
    "\n",
    "pack_of_models = []\n",
    "my_models = []\n",
    "for train_index, test_index in my_kf.split(X_pd):\n",
    "    X_train, X_test = X_pd[train_index], X_pd[test_index]\n",
    "    y_train, y_test = y_pd[train_index], y_pd[test_index]\n",
    "    my_models = []\n",
    "    my_models.append(KNeighborsRegressor(n_neighbors=36, p = 1, weights='distance', n_jobs=-1).fit(X_train, y_train))\n",
    "    my_models.append(RandomForestRegressor(n_estimators=80, n_jobs = -1).fit(X_train, y_train))\n",
    "    my_models.append(GradientBoostingRegressor(n_estimators=100, max_depth=9).fit(X_train, y_train))\n",
    "    my_models.append(HistGradientBoostingRegressor(max_iter=160, max_depth=9, max_leaf_nodes = 40).fit(X_train, y_train))\n",
    "    print('Base Models')\n",
    "    meta_features = []\n",
    "    for elem in X_test:\n",
    "        tmp_res = np.array([])\n",
    "        for model in my_models:\n",
    "            tmp_res = np.hstack([tmp_res, model.predict(elem.reshape(1, len(elem)))])\n",
    "        meta_features.append(tmp_res)\n",
    "    meta_features = np.array(meta_features)\n",
    "    pack_of_models.append([my_models, LinearRegression().fit(meta_features, y_test)])\n",
    "    print('Meta LR')\n",
    "    \n",
    "print('Model is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de098879",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test has started\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     tmp_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m model_string[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m----> 9\u001b[0m         tmp_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([tmp_res, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m     10\u001b[0m     tmp_answ\u001b[38;5;241m.\u001b[39mappend(model_string[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(tmp_res\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(tmp_res))))\n\u001b[0;32m     11\u001b[0m tmp_answ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tmp_answ)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:229\u001b[0m, in \u001b[0;36mKNeighborsRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict the target for the provided data.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     weights \u001b[38;5;241m=\u001b[39m _get_weights(neigh_dist, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\n\u001b[0;32m    233\u001b[0m     _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 752\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1717\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1716\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1717\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1719\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1889\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1886\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   1887\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 1889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1435\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1433\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n\u001b[0;32m   1434\u001b[0m ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1435\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreading\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_n_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal for euclidean norm.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;66;03m# TODO: do it also for other norms.\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m     np\u001b[38;5;241m.\u001b[39mfill_diagonal(ret, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:252\u001b[0m, in \u001b[0;36mPoolManagerMixin.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[0;32m    253\u001b[0m         SafeFunction(func), callback\u001b[38;5;241m=\u001b[39mcallback)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:407\u001b[0m, in \u001b[0;36mThreadingBackend._get_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"Lazily initialize the thread pool\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03mThe actual pool of worker threads is only initialized at the first\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03mcall to apply_async.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[43mThreadPool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py:927\u001b[0m, in \u001b[0;36mThreadPool.__init__\u001b[1;34m(self, processes, initializer, initargs)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initargs\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m--> 927\u001b[0m     \u001b[43mPool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py:196\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_taskqueue \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mSimpleQueue()\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# The _change_notifier queue exist to wake up self._handle_workers()\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# when the cache (self._cache) is empty or when there is a change in\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# the _state variable of the thread that runs _handle_workers.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_change_notifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSimpleQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m _PoolCache(notifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_change_notifier)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maxtasksperchild \u001b[38;5;241m=\u001b[39m maxtasksperchild\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py:113\u001b[0m, in \u001b[0;36mBaseContext.SimpleQueue\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m'''Returns a queue object'''\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqueues\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleQueue\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSimpleQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\queues.py:341\u001b[0m, in \u001b[0;36mSimpleQueue.__init__\u001b[1;34m(self, ctx)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, ctx):\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduplex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mLock()\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mpoll\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py:554\u001b[0m, in \u001b[0;36mPipe\u001b[1;34m(duplex)\u001b[0m\n\u001b[0;32m    551\u001b[0m     access \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mGENERIC_WRITE\n\u001b[0;32m    552\u001b[0m     obsize, ibsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, BUFSIZE\n\u001b[1;32m--> 554\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateNamedPipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFILE_FLAG_OVERLAPPED\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFILE_FLAG_FIRST_PIPE_INSTANCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE_TYPE_MESSAGE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE_READMODE_MESSAGE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE_WAIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mibsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNMPWAIT_WAIT_FOREVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# default security descriptor: the handle cannot be inherited\u001b[39;49;00m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNULL\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m h2 \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateFile(\n\u001b[0;32m    564\u001b[0m     address, access, \u001b[38;5;241m0\u001b[39m, _winapi\u001b[38;5;241m.\u001b[39mNULL, _winapi\u001b[38;5;241m.\u001b[39mOPEN_EXISTING,\n\u001b[0;32m    565\u001b[0m     _winapi\u001b[38;5;241m.\u001b[39mFILE_FLAG_OVERLAPPED, _winapi\u001b[38;5;241m.\u001b[39mNULL\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m _winapi\u001b[38;5;241m.\u001b[39mSetNamedPipeHandleState(\n\u001b[0;32m    568\u001b[0m     h2, _winapi\u001b[38;5;241m.\u001b[39mPIPE_READMODE_MESSAGE, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Test has started')\n",
    "new_meta_features = []\n",
    "my_result = []\n",
    "for elem in X_pd:\n",
    "    tmp_answ = []    \n",
    "    for model_string in pack_of_models:\n",
    "        tmp_res = np.array([])\n",
    "        for model in model_string[0]:\n",
    "            tmp_res = np.hstack([tmp_res, model.predict(elem.reshape(1, len(elem)))])\n",
    "        tmp_answ.append(model_string[1].predict(tmp_res.reshape(1,len(tmp_res))))\n",
    "    tmp_answ = np.array(tmp_answ)\n",
    "    my_result.append(np.mean(tmp_answ))\n",
    "\n",
    "my_result = np.array(my_result)\n",
    "    \n",
    "\n",
    "accur = mean_squared_log_error(y_pd, abs(my_result), squared=False)\n",
    "print(accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c79614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test has started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6745565.48669781,  5432736.76855097,  4055334.72111829, ...,\n",
       "        7601768.57051382,  3687879.40889432, 10820401.64183781])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test has started')\n",
    "new_meta_features = []\n",
    "my_result = []\n",
    "for elem in testX:\n",
    "    tmp_answ = []    \n",
    "    for model_string in pack_of_models:\n",
    "        tmp_res = np.array([])\n",
    "        for model in model_string[0]:\n",
    "            tmp_res = np.hstack([tmp_res, model.predict(elem.reshape(1, len(elem)))])\n",
    "        tmp_answ.append(model_string[1].predict(tmp_res.reshape(1,len(tmp_res))))\n",
    "    tmp_answ = np.array(tmp_answ)\n",
    "    my_result.append(np.mean(tmp_answ))\n",
    "\n",
    "my_result = np.array(my_result)\n",
    "my_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e727ee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6745565.,  5432737.,  4055335., ...,  7601769.,  3687879.,\n",
       "       10820402.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_result.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dda0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_answ = pd.DataFrame({'id': range(1,1+6095), 'prediction': my_result.round()})\n",
    "my_answ.to_csv('Doynichenko_Maxim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35677c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
